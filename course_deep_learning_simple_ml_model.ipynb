{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrycL0k4sw2i8VRgRQW8Ts"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create a simple ML model\n",
        "\n",
        "We consider the following sets of numbers:\n",
        "\n",
        "| X: | -1 | 0 | 1 | 2 | 3 | 4 |\n",
        "| --- |--- | --- | --- |--- | --- | --- |\n",
        "| Y: | -2 | 1 | 4 | 7 | 10 | 13 |\n",
        "\n",
        "Can you see the relationship between them?\n",
        "\n",
        "A human can look at these numbers, try to guess, and would come up with the relationship Y=3X+1.\n",
        "\n",
        "How would you train a neural network to do the equivalent task?<br>\n",
        "Using data!<br>\n",
        "By feeding it with a set of X's and a set of Y's, it should be able to figure out the relationship between them.\n",
        "\n",
        "That's what we will do in the following."
      ],
      "metadata": {
        "id": "E2YkZjMiM_Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n",
        "\n",
        "We import:\n",
        "* `tensorflow`,\n",
        "* `keras`: the framework for defining a neural network as a set of sequential layers,\n",
        "* `numpy`."
      ],
      "metadata": {
        "id": "hRhMA7JyQVsZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h7w8O2nRM2vZ"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define and compile the neural network\n",
        "\n",
        "Next, we create the simplest possible neural network.\n",
        "\n",
        "It has one layer, that layer has one neuron, and the input shape to it is only one value.\n",
        "\n",
        "We use the **`tf.keras.Sequential`** class to build a neural network model. It represents a linear stack of layers, where data flows sequentially from one layer to the next.\n"
      ],
      "metadata": {
        "id": "yxLqcVuMRPhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model\n",
        "model = tf.keras.Sequential([\n",
        "    keras.layers.Dense(units=1, input_shape=[1])\n",
        "])"
      ],
      "metadata": {
        "id": "II8mdxMURf9r"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we write the code to compile the neural network.\n",
        "\n",
        "When we do so, we need to specify two functions—a **`loss`** and an **`optimizer`**.\n",
        "\n",
        "The **`loss`** function measures the guessed answers against the known correct answers and measures how well or badly it did.\n",
        "\n",
        "Next, the model uses the **`optimizer`** function to make another guess.\n",
        "\n",
        "Based on the **`loss`** function's result, it tries to minimize the loss.\n",
        "\n",
        "The model repeats that for the number of *epochs*, which we'll see shortly.\n",
        "\n",
        "First, we tell the model to use **`mean_squared_error`** for the loss and stochastic gradient descent (**`sgd`**) for the optimizer."
      ],
      "metadata": {
        "id": "Pjf1dgEGR1PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model, specify loss function and optimizer function\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "sik-r8eDTG79"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Provide the data\n",
        "\n",
        "Next, we feed some data.\n",
        "\n",
        "In this case, we take the six X and six Y variables from earlier."
      ],
      "metadata": {
        "id": "KDcNOrfHTUtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set data\n",
        "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-2.0, 1.0, 4.0, 7.0, 10.0, 13.0], dtype=float)"
      ],
      "metadata": {
        "id": "NmC7EWqgTmhW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have all the code we need to define the neural network.\n",
        "\n",
        "The next step is to train it to see if it can infer the patterns between those numbers and use them to create a model."
      ],
      "metadata": {
        "id": "ezwsIehiTzLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the neural network\n",
        "\n",
        "The process of training the neural network, where it learns the relationship between the X's and Y's, is in the **`model.fit`** call.\n",
        "\n",
        "That's where it will go through the loop before making a guess, measuring how good or bad it is (the loss), or using the optimizer to make another guess.\n",
        "\n",
        "It will do that for the number of epochs that we specify.\n",
        "\n",
        "When we run that code, we'll see the loss will be printed out for each epoch."
      ],
      "metadata": {
        "id": "RZOR3pzUUCO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model, verbose=0: silent mode.\n",
        "model.fit(xs, ys, epochs=500, verbose=0)"
      ],
      "metadata": {
        "id": "gblVoGYpUXMH",
        "collapsed": true,
        "outputId": "1c7334e0-53d3-4f7c-f6e9-00d266fe1c70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c5a146e5f40>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, we can see that for the first few epochs, the loss value is quite large, but it's getting smaller with each step.\n",
        "\n",
        "As the training progresses, the loss soon gets very small.\n",
        "\n",
        "By the time the training is done, the loss is extremely small, showing that our model is doing a great job of inferring the relationship between the numbers.\n",
        "\n",
        "We probably don't need all 500 epochs and can experiment with different amounts.\n",
        "\n",
        "As we can see from the example, the loss is really small after only 50 epochs, so that might be enough!"
      ],
      "metadata": {
        "id": "DF3f4UwhU0Ph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Model\n",
        "\n",
        "The **`Model.evaluate`** method checks the model's performance, usually on a validation set or test set."
      ],
      "metadata": {
        "id": "JwQL8bveHyPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = np.array([5.0, 6.0, 7.0, 8.0, 9.0], dtype=float)\n",
        "y_test = np.array([16.0, 19.0, 22.0, 25.0, 28.0], dtype=float)\n",
        "\n",
        "# evaluate the model\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "metadata": {
        "id": "8sifTOjdIDDY",
        "outputId": "057bc984-6db0-4f36-a490-053e0e61c086",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - 41ms/step - loss: 1.9424e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.9423932826612145e-06"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the model\n",
        "\n",
        "We have a model that has been trained to learn the relationship between X and Y.\n",
        "\n",
        "We can use the **`model.predict`** method to have it figure out the Y for a previously unknown X.\n",
        "\n",
        "For example, if X is 10, what Y will be?"
      ],
      "metadata": {
        "id": "Sojrje1MVU7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "x = np.array([10.0])\n",
        "print(model.predict(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc_tnyK9VrOe",
        "outputId": "e396897a-4a65-48f8-8ae4-e542229d810e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "[[31.002317]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "We covered most of the concepts in ML that we'll use in far more complex scenarios.\n",
        "\n",
        "We learned how to train a neural network to spot the relationship between two sets of numbers by defining the network.\n",
        "\n",
        "We defined a set of layers (in this case only one) that contained neurons (also in this case, only one), which we then compiled with a loss function and an optimizer.\n",
        "\n",
        "The collection of a network, loss function, and optimizer handles the process of guessing the relationship between the numbers, measuring how well they did, and then generating new parameters for new guesses."
      ],
      "metadata": {
        "id": "Mar3_c6zfpJ_"
      }
    }
  ]
}